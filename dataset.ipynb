{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will have to go to \\BengaliSummarization\\Dataset \n",
    "# txt to csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# read the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\bensumm'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filepath\n",
    "pwd = os.getcwd()\n",
    "path = pwd + '/BengaliSummarization/Dataset'\n",
    "\n",
    "# if os.path.exists(path):\n",
    "    # print(\"File found\")\n",
    "\n",
    "# Two dataset directories, extract directory names\n",
    "# print(os.listdir(path)) #['BNLPC', 'NCTB']\n",
    "\n",
    "# go to all subdirectories directory by directory\n",
    "dataframe = pd.DataFrame()\n",
    "texts = []\n",
    "\n",
    "\n",
    "for directory in os.listdir(path):\n",
    "    # outputFileName = directory \n",
    "    for subdirectory in os.listdir(path + '/' + directory):\n",
    "        if directory == 'BNLPC':\n",
    "            for file in os.listdir(path + '/' + directory + '/' + subdirectory):\n",
    "                if file == 'Documents':\n",
    "                    for document in os.listdir(path + '/' + directory + '/' + subdirectory + '/' + file):\n",
    "                        if document.endswith('.txt'):\n",
    "                            # print(\"File found at \" + path + '/' + directory + '/' + subdirectory + '/' + file + '/' + document)\n",
    "                            with open(path + '/' + directory + '/' + subdirectory + '/' + file + '/' + document, 'r', encoding='utf-8') as f:\n",
    "                                data = f.read()\n",
    "                                title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                                text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                                # dataframe.add({'Title': title, 'Text': text})\n",
    "                                texts.append(text)\n",
    "\n",
    "\n",
    "                                # create a csv file\n",
    "                                # with open(filename + '.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                                #     fieldnames = ['Title', 'Text']\n",
    "                                #     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                                #     writer.writeheader()\n",
    "                                #     writer.writerow({'Title': title, 'Text': text})\n",
    "\n",
    "# data\n",
    "# # ''Title: \\nধানমন্ডি লেক থেকে কিশোরের লাশ উদ্ধার \\n\\nText: \\n  সুদীপ্ত দত্ত অর্জুন নামে এক কিশোরের লাশ আজ মঙ্গলবার সকালে ধানমন্ডি লেক থেকে উদ্ধার করেছে পুলিশ। সুদীপ্ত রাজধানীর রাইফেলস স্কুল অ্যান্ড কলেজের শিক্ষার্থী। সে এ বছরের এইচএসসি পরীক্ষার্থী।\\nআজ সকাল সাড়ে আটটার দিকে ধানমন্ডি লেকে একজনের লাশ ভাসতে দেখে পুলিশে খবর দেয় সেখানে ঘুরতে আসা কয়েকজন ব্যক্তি। এরপর পুলিশ গিয়ে লাশ উদ্ধার করে। অর্জুন রায়ের বাজারে তার পরিবারের সঙ্গে থাকত।\\nধানমন্ডি থানার ভারপ্রাপ্ত কর্মকর্তা (ওসি-তদন্ত) হেলালউদ্দিন প্রথম আলোকে বলেন, ছেলেটির স্বাস্থ্যগত কিছু সমস্যা ছিল। তার মুখ থেকে দুর্গন্ধ বের হতো। এ নিয়ে অনেকে অনেক কথা বলতো। তা ছাড়া বাসা থেকে পড়াশোনার জন্য খুব চাপ দেওয়া হতো। পরিবারের ওপর রাগ করে গত ২৮ ফেব্রুয়ারি সে বাসা থেকে বের হয়ে যায়। এরপর তার পরিবারের পক্ষ থেকে থানায় একটি সাধারণ ডায়েরি (জিডি) করা হয়। সেখানে রাগ করে বাসা থেকে বের হওয়ার কথার উল্লেখ করা হয়েছে। \\nওই কর্মকর্তা জানান, পুলিশ লাশ এনে থানায় রাখে। এরপর ছেলেটির মা ছন্দা দত্ত ও বোন এসে লাশ শনাক্ত করে। ময়নাতদন্তের জন্য লাশ ঢাকা মেডিকেল কলেজে পাঠানো হয়েছে বলে জানান তিনি। দুই ভাই বোনের মধ্যে অর্জুন ছোট।\\n\\n\\n''\n",
    "\n",
    "# # extract title and text\n",
    "# title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "# text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "\n",
    "# print(title)\n",
    "# print(text)\n",
    "\n",
    "# texts.size\n",
    "pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd\n",
    "\n",
    "path = pwd + '/BengaliSummarization/Dataset'\n",
    "\n",
    "filenames = [\n",
    "    'BNLPC_Dataset1.csv',\n",
    "    'BNLPC_Dataset2.csv',\n",
    "    'NCTB_Dataset.csv'\n",
    "]\n",
    "\n",
    "BNLPC_Dataset1 = []\n",
    "BNLPC_Dataset2 = []\n",
    "NCTB_Dataset = []\n",
    "\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset1\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        BNLPC_Dataset1.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset2\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        BNLPC_Dataset2.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "    elif string[0] == 'NCTB':\n",
    "        path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB\\\\Source'\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith('.txt'):\n",
    "                with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                    # print(f.read())\n",
    "                    data = f.read()\n",
    "                    NCTB_Dataset.append({'Text': data, 'Filename': file})\n",
    "# BNLPC_Dataset2\n",
    "# NCTB_Dataset\n",
    "                    \n",
    "# create csv files\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Title', 'Text', 'Filename']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset1:\n",
    "                    writer.writerow(data)\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Title', 'Text', 'Filename']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset2:\n",
    "                    writer.writerow(data)\n",
    "    elif string[0] == 'NCTB':\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Text', 'Filename']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()\n",
    "            for data in NCTB_Dataset:\n",
    "                writer.writerow({'Text': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCTB_Dataset\n",
    "\n",
    "df = pd.read_csv('d:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB_Dataset.csv')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only need this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "\n",
    "path = pwd + '/BengaliSummarization/Dataset'\n",
    "\n",
    "filenames = [\n",
    "    'BNLPC_Dataset1.csv',\n",
    "    'BNLPC_Dataset2.csv',\n",
    "    'NCTB_Dataset.csv'\n",
    "]\n",
    "\n",
    "BNLPC_Dataset1 = []\n",
    "BNLPC_Dataset2 = []\n",
    "NCTB_Dataset = []\n",
    "\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset1\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        # BNLPC_Dataset1.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "                        # only text, no filename\n",
    "                        BNLPC_Dataset1.append(text)\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset2\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        # remove [] and '' and \"\"\n",
    "                        # title = re.sub(r'\\[\\'', '', str(title))\n",
    "                        # title = re.sub(r'\\'\\]', '', str(title))\n",
    "                        # title = re.sub(r'\\\"', '', str(title))\n",
    "                        # title = re.sub(r'\\'', '', str(title))\n",
    "                        # title = re.sub(r'\\[', '', str(title))\n",
    "                        # title = re.sub(r'\\]', '', str(title))\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        # BNLPC_Dataset2.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "                        # only text, no filename\n",
    "                        # print(text)\n",
    "                        # print(title)\n",
    "                        BNLPC_Dataset2.append(text)\n",
    "                        # print(BNLPC_Dataset2)\n",
    "    elif string[0] == 'NCTB':\n",
    "        path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB\\\\Source'\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith('.txt'):\n",
    "                with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                    # print(f.read())\n",
    "                    data = f.read()\n",
    "                    # NCTB_Dataset.append({'Text': data, 'Filename': file})\n",
    "                    # only text, no filename\n",
    "                    NCTB_Dataset.append(data)\n",
    "# BNLPC_Dataset2\n",
    "# NCTB_Dataset\n",
    "\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Text']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset1:\n",
    "                    print({'Text': data})\n",
    "                    writer.writerow({'Text': data})\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Text']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset2:\n",
    "                    writer.writerow({'Text': data})\n",
    "    elif string[0] == 'NCTB':\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Text']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()\n",
    "            for data in NCTB_Dataset:\n",
    "                writer.writerow({'Text': data})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('d:\\\\bensumm\\\\BNLPC_Dataset1.csv')\n",
    "\n",
    "df\n",
    "\n",
    "# add a column to the dataframe\n",
    "df['Summary'] = ''\n",
    "df\n",
    "\n",
    "path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset1\\\\Summaries'\n",
    "\n",
    "# if os.path.exists(path):\n",
    "    # print(\"File found\")\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('1.txt'):\n",
    "        with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "            # print(data)\n",
    "\n",
    "            # add summary to the dataframe\n",
    "            # print(file) #Document_100_Summary_1.txt\n",
    "            # get the document number\n",
    "            document = re.findall(r'Document_(.*?)_Summary', file)\n",
    "            # print(document)\n",
    "            # filename Document_1.txt\n",
    "            df.loc[df['Filename'] == 'Document_' + document[0] + '.txt', 'Summary'] = data\n",
    "        \n",
    "df\n",
    "\n",
    "# drop text and filename columns and then save the dataframe to a csv file\n",
    "df = df.drop(columns=['Title', 'Filename'])\n",
    "df.to_csv('d:\\\\bensumm\\\\BNLPC_Dataset1.csv', index=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('d:\\\\bensumm\\\\BNLPC_Dataset2.csv')\n",
    "df['Summary'] = ''\n",
    "\n",
    "path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset2\\\\Summaries'\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('1.txt'):\n",
    "        with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "            # print(data)\n",
    "\n",
    "            # add summary to the dataframe\n",
    "            # print(file) #Document_100_Summary_1.txt\n",
    "            # get the document number\n",
    "            document = re.findall(r'Document_(.*?)_Summary', file)\n",
    "            # print(document)\n",
    "            # filename Document_1.txt\n",
    "            df.loc[df['Filename'] == 'Document_' + document[0] + '.txt', 'Summary'] = data\n",
    "\n",
    "df = df.drop(columns=['Title', 'Filename'])\n",
    "df.to_csv('d:\\\\bensumm\\\\BNLPC_Dataset2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও ১০ মামলায় হাইকোর্ট থেকে জামিন পেয়েছেন সাবেক মন্ত্রী আবদুল লতিফ সিদ্দিকী\\nগত বছর সেপ্টেম্বরে যুক্তরাষ্ট্রের নিউইয়র্কে এক অনুষ্ঠানে হজ ও তাবলিগ জামাত নিয়ে বিরূপ মন্তব্য করে সমালোচনার মুখে পড়েন আবদুল লতিফ সিদ্দিকী\\nনির্ধারিত সময়ে আদালতে হাজির না হওয়ায় প্রতিটি মামলায় তাঁর বিরুদ্ধে গ্রেপ্তারি পরোয়ানা জারি করেন আদালত\\nএই দশ মামলায় লতিফকে অন্তবর্তীকালীন জামিন দেওয়ার পাশাপাশি মামলাগুলোর কার্যক্রম ছয় মাসের জন্য স্থগিত করেছে আদালত\\nএসব মামলা কেন বাতিল করা হবে না তা জানতে চেয়ে একটি রুলও জারি করা হয়েছে, মামলার বাদী ও সরকারকে চার সপ্তাহের মধ্যে যার জবাব দিতে হবে\\nআদেশের পর ডেপুটি অ্যাটর্নি জেনারেল মনিরুজ্জামান কবির বলেন, \\\\\"এ নিয়ে মোট ১৭টি মামলায় লতিফ সিদ্দিকী জামিন পেলেন। তবে আরও পাঁচটি মামলা থাকায় তিনি আপাতত মুক্তি পাচ্ছেন না।\\\\\"\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('d:\\\\bensumm\\\\BNLPC_Dataset1.csv')\n",
    "df['Text'][0]\n",
    "# \"['  ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও ১০ মামলায় হাইকোর্ট থেকে জামিন পেয়েছেন সাবেক মন্ত্রী আবদুল লতিফ সিদ্দিকী। বিচারপতি মো. নিজামুল হক ও বিচারপতি মো. ফরিদ আহমদ শিবলীর সমন্বয়ে ঘটিত হাইকোর্ট বেঞ্চ আজ মঙ্গলবার এ আদেশ দেন।']\"\n",
    "\n",
    "df['Summary'][0]\n",
    "# 'ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও ১০ মামলায় হাইকোর্ট থেকে জামিন পেয়েছেন সাবেক মন্ত্রী আবদুল লতিফ সিদ্দিকী\\nগত বছর সেপ্টেম্বরে যুক্তরাষ্ট্রের নিউইয়র্কে এক অনুষ্ঠানে হজ ও তাবলিগ জামাত নিয়ে বিরূপ মন্তব্য করে সমালোচনার মুখে পড়েন আবদুল লতিফ সিদ্দিকী\\nনির্ধারিত সময়ে আদালতে হাজির না হওয়ায় প্রতিটি মামলায় তাঁর বিরুদ্ধে গ্রেপ্তারি পরোয়ানা জারি করেন আদালত\\nএই দশ মামলায় লতিফকে অন্তবর্তীকালীন জামিন দেওয়ার পাশাপাশি মামলাগুলোর কার্যক্রম ছয় মাসের জন্য স্থগিত করেছে আদালত\\nএসব মামলা কেন বাতিল করা হবে না তা জানতে চেয়ে একটি রুলও জারি করা হয়েছে, মামলার বাদী ও সরকারকে চার সপ্তাহের মধ্যে যার জবাব দিতে হবে\\nআদেশের পর ডেপুটি অ্যাটর্নি জেনারেল মনিরুজ্জামান কবির বলেন, \\\\\"এ নিয়ে মোট ১৭টি মামলায় লতিফ সিদ্দিকী জামিন পেলেন। তবে আরও পাঁচটি মামলা থাকায় তিনি আপাতত মুক্তি পাচ্ছেন না।\\\\\"\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB\\\\Source'\n",
    "with open(\"NCTB_Dataset.csv\", 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Text', 'Summary']\n",
    "\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.txt'):\n",
    "            with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                data = f.read()\n",
    "            with open('d:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB\\\\Summary\\\\' + file, 'r', encoding='utf-8') as f:\n",
    "                summary = f.read()\n",
    "                \n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([data, summary])\n",
    "\n",
    "        \n",
    "\n",
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'মানুষের সুন্দর মুখ দেখে আনন্দিত হয়ো না। স্বভাবে সে সুন্দর নয়, দেখতে সুন্দর হলেও তার স্বভাব, তার স্পর্শ, তার রীতিনীতিকে মানুষ ঘৃণা করে। দুঃস্বভাবের মানুষ মানুষের হৃদয়ে জ্বালা ও বেদনা দেয়। তার সুন্দর মুখে মানুষ তৃপ্তি পায় না। অবোধ লোকেরা মানুষের রূপ দেখে মুগ্ধ হয় এবং তার ফল ভোগ করে। যার স্বভাব মন্দ, সে নিজেও দুষ্ক্রিয়াশীল, মিথ্যাবাদী, দুর্মতিকে ঘৃণা করে। মানুষ নিজে স্বভাবে সুন্দর না হলেও সে স্বভাবের সৌন্দর্যকে ভালোবাসে। স্বভাব গঠনে কঠিন পরিশ্রম ও সাধনা চাই, নইলে শয়তানকে পরাজিত করা সম্ভব নয়।\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('d:\\\\bensumm\\\\NCTB_Dataset.csv')\n",
    "\n",
    "df\n",
    "\n",
    "df['Text'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
