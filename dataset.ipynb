{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will have to go to \\BengaliSummarization\\Dataset \n",
    "# txt to csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# read the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\bensumm'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filepath\n",
    "pwd = os.getcwd()\n",
    "path = pwd + '/BengaliSummarization/Dataset'\n",
    "\n",
    "# if os.path.exists(path):\n",
    "    # print(\"File found\")\n",
    "\n",
    "# Two dataset directories, extract directory names\n",
    "# print(os.listdir(path)) #['BNLPC', 'NCTB']\n",
    "\n",
    "# go to all subdirectories directory by directory\n",
    "dataframe = pd.DataFrame()\n",
    "texts = []\n",
    "\n",
    "\n",
    "for directory in os.listdir(path):\n",
    "    # outputFileName = directory \n",
    "    for subdirectory in os.listdir(path + '/' + directory):\n",
    "        if directory == 'BNLPC':\n",
    "            for file in os.listdir(path + '/' + directory + '/' + subdirectory):\n",
    "                if file == 'Documents':\n",
    "                    for document in os.listdir(path + '/' + directory + '/' + subdirectory + '/' + file):\n",
    "                        if document.endswith('.txt'):\n",
    "                            # print(\"File found at \" + path + '/' + directory + '/' + subdirectory + '/' + file + '/' + document)\n",
    "                            with open(path + '/' + directory + '/' + subdirectory + '/' + file + '/' + document, 'r', encoding='utf-8') as f:\n",
    "                                data = f.read()\n",
    "                                title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                                text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                                # dataframe.add({'Title': title, 'Text': text})\n",
    "                                texts.append(text)\n",
    "\n",
    "\n",
    "                                # create a csv file\n",
    "                                # with open(filename + '.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                                #     fieldnames = ['Title', 'Text']\n",
    "                                #     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                                #     writer.writeheader()\n",
    "                                #     writer.writerow({'Title': title, 'Text': text})\n",
    "\n",
    "# data\n",
    "# # ''Title: \\nধানমন্ডি লেক থেকে কিশোরের লাশ উদ্ধার \\n\\nText: \\n  সুদীপ্ত দত্ত অর্জুন নামে এক কিশোরের লাশ আজ মঙ্গলবার সকালে ধানমন্ডি লেক থেকে উদ্ধার করেছে পুলিশ। সুদীপ্ত রাজধানীর রাইফেলস স্কুল অ্যান্ড কলেজের শিক্ষার্থী। সে এ বছরের এইচএসসি পরীক্ষার্থী।\\nআজ সকাল সাড়ে আটটার দিকে ধানমন্ডি লেকে একজনের লাশ ভাসতে দেখে পুলিশে খবর দেয় সেখানে ঘুরতে আসা কয়েকজন ব্যক্তি। এরপর পুলিশ গিয়ে লাশ উদ্ধার করে। অর্জুন রায়ের বাজারে তার পরিবারের সঙ্গে থাকত।\\nধানমন্ডি থানার ভারপ্রাপ্ত কর্মকর্তা (ওসি-তদন্ত) হেলালউদ্দিন প্রথম আলোকে বলেন, ছেলেটির স্বাস্থ্যগত কিছু সমস্যা ছিল। তার মুখ থেকে দুর্গন্ধ বের হতো। এ নিয়ে অনেকে অনেক কথা বলতো। তা ছাড়া বাসা থেকে পড়াশোনার জন্য খুব চাপ দেওয়া হতো। পরিবারের ওপর রাগ করে গত ২৮ ফেব্রুয়ারি সে বাসা থেকে বের হয়ে যায়। এরপর তার পরিবারের পক্ষ থেকে থানায় একটি সাধারণ ডায়েরি (জিডি) করা হয়। সেখানে রাগ করে বাসা থেকে বের হওয়ার কথার উল্লেখ করা হয়েছে। \\nওই কর্মকর্তা জানান, পুলিশ লাশ এনে থানায় রাখে। এরপর ছেলেটির মা ছন্দা দত্ত ও বোন এসে লাশ শনাক্ত করে। ময়নাতদন্তের জন্য লাশ ঢাকা মেডিকেল কলেজে পাঠানো হয়েছে বলে জানান তিনি। দুই ভাই বোনের মধ্যে অর্জুন ছোট।\\n\\n\\n''\n",
    "\n",
    "# # extract title and text\n",
    "# title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "# text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "\n",
    "# print(title)\n",
    "# print(text)\n",
    "\n",
    "# texts.size\n",
    "pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd\n",
    "\n",
    "path = pwd + '/BengaliSummarization/Dataset'\n",
    "\n",
    "filenames = [\n",
    "    'BNLPC_Dataset1.csv',\n",
    "    'BNLPC_Dataset2.csv',\n",
    "    'NCTB_Dataset.csv'\n",
    "]\n",
    "\n",
    "BNLPC_Dataset1 = []\n",
    "BNLPC_Dataset2 = []\n",
    "NCTB_Dataset = []\n",
    "\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset1\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        BNLPC_Dataset1.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset2\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        BNLPC_Dataset2.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "    elif string[0] == 'NCTB':\n",
    "        path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB\\\\Source'\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith('.txt'):\n",
    "                with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                    # print(f.read())\n",
    "                    data = f.read()\n",
    "                    NCTB_Dataset.append({'Text': data, 'Filename': file})\n",
    "# BNLPC_Dataset2\n",
    "# NCTB_Dataset\n",
    "                    \n",
    "# create csv files\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Title', 'Text', 'Filename']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset1:\n",
    "                    writer.writerow(data)\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Title', 'Text', 'Filename']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset2:\n",
    "                    writer.writerow(data)\n",
    "    elif string[0] == 'NCTB':\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Text', 'Filename']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()\n",
    "            for data in NCTB_Dataset:\n",
    "                writer.writerow({'Text': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCTB_Dataset\n",
    "\n",
    "df = pd.read_csv('d:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB_Dataset.csv')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only need this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd\n",
    "\n",
    "path = pwd + '/BengaliSummarization/Dataset'\n",
    "\n",
    "filenames = [\n",
    "    'BNLPC_Dataset1.csv',\n",
    "    'BNLPC_Dataset2.csv',\n",
    "    'NCTB_Dataset.csv'\n",
    "]\n",
    "\n",
    "BNLPC_Dataset1 = []\n",
    "BNLPC_Dataset2 = []\n",
    "NCTB_Dataset = []\n",
    "\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset1\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        # BNLPC_Dataset1.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "                        # only text, no filename\n",
    "                        BNLPC_Dataset1.append(text)\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\BNLPC\\\\Dataset2\\\\Documents'\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                        # print(f.read())\n",
    "                        # extract title and text\n",
    "                        data = f.read()\n",
    "                        title = re.findall(r'Title: \\n(.*?)\\n', data)\n",
    "                        if len(title) == 0:\n",
    "                            title = re.findall(r'Title: (.*?)\\n', data)\n",
    "                        text = re.findall(r'Text: \\n(.*?)\\n', data)\n",
    "                        # BNLPC_Dataset2.append({'Title': title, 'Text': text, 'Filename': file})\n",
    "                        # only text, no filename\n",
    "                        BNLPC_Dataset2.append(text)\n",
    "    elif string[0] == 'NCTB':\n",
    "        path = 'd:\\\\bensumm\\\\BengaliSummarization\\\\Dataset\\\\NCTB\\\\Source'\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith('.txt'):\n",
    "                with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "                    # print(f.read())\n",
    "                    data = f.read()\n",
    "                    # NCTB_Dataset.append({'Text': data, 'Filename': file})\n",
    "                    # only text, no filename\n",
    "                    NCTB_Dataset.append(data)\n",
    "# BNLPC_Dataset2\n",
    "# NCTB_Dataset\n",
    "\n",
    "for filename in filenames:\n",
    "    string = filename.split('_')\n",
    "    if string[0] == 'BNLPC':\n",
    "        if string[1] == 'Dataset1.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Text']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset1:\n",
    "                    writer.writerow({'Text': data})\n",
    "        elif string[1] == 'Dataset2.csv':\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = ['Text']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "                for data in BNLPC_Dataset2:\n",
    "                    writer.writerow({'Text': data})\n",
    "    elif string[0] == 'NCTB':\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Text']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()\n",
    "            for data in NCTB_Dataset:\n",
    "                writer.writerow({'Text': data})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
