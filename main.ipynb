{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# need to read dataset from huggingface\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import json\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# huggingface datasets\n",
    "# ! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def data_loader(index):\n",
    "    url = 'shahidul034/text_summarization_dataset'\n",
    "    url = url + str(index)\n",
    "    dataset = load_dataset(url)\n",
    "\n",
    "    path = 'text_summarization_dataset' + str(index) + '.csv'\n",
    "    dataset['train'].to_csv(path)\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# initialize dataframe\n",
    "df = pd.DataFrame(columns=['title', 'content'])\n",
    "for i in range(1, 10):\n",
    "    data_loader(i)\n",
    "    df\n",
    "# index = 2\n",
    "\n",
    "# dataset = load_dataset(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_summarization_dataset8.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/Hp/.cache/huggingface/datasets/shahidul034___parquet/shahidul034--text_summarization_dataset2-8ef6ba38aa6d1a60/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733ff39105514070990dbdea451ce011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'shahidul034/text_summarization_dataset'\n",
    "url = url + \"2\"\n",
    "dataset = load_dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 105252\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'শাহজালালে বিমানের টয়লেটে মিলল ৪০ স্বর্ণের বার',\n",
       " 'content': ' কাস্টমস কর্তৃপক্ষ সূত্র জানায়, কাস্টমস গোয়েন্দা ও তদন্ত অধিদপ্তরের মহাপরিচালকের কাছে সংবাদ আসে সংযুক্ত আরব আমিরাতের আবুধাবি থেকে চট্টগ্রাম হয়ে আসা বিমান বাংলাদেশ এয়ারলাইনসের বিমানে অবৈধভাবে চোরাচালানকৃত স্বর্ণ বহন করা হচ্ছে। এর প্রেক্ষিতে কাস্টমস গোয়েন্দা ও তদন্ত অধিদপ্তরের যুগ্ম মহাপরিচালক আরেফিন খানের নির্দেশে উপপরিচালক আহমেদুর রেজা চৌধুরীর নেতৃত্বে কাস্টমস গোয়েন্দার একটি দল ১০ নম্বর বোর্ডিং ব্রিজের সামনে অবস্থান নেয়।পরে কাস্টমস গোয়েন্দা দল বিমানের ভেতরে প্রবেশ করে এবং বিমানের টয়লেট থেকে বিশেষভাবে লুকিয়ে রাখা ৪০টি স্বর্ণবার উদ্ধার করে। যার মোট ওজন চর কেজি ৬৪০ গ্রাম। আটক স্বর্ণের বাজারমূল্য আনুমানিক তিন কোটি ২৪ লাখ ৮০ হাজার টাকা। এ বিষয়ে বিমানবন্দর থানায় মামলা দায়েরের প্রক্রিয়া চলছে।'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['শাহজালাল',\n",
       " 'আনত',\n",
       " '##র',\n",
       " '##জাতিক',\n",
       " 'বিমান',\n",
       " '##বন',\n",
       " '##দরে',\n",
       " 'বিমান',\n",
       " 'বাংলাদেশ',\n",
       " 'এ',\n",
       " '##যার',\n",
       " '##লাইন',\n",
       " '##সের',\n",
       " 'একটি',\n",
       " 'ফলা',\n",
       " '##ইট',\n",
       " '##ের',\n",
       " 'ট',\n",
       " '##য',\n",
       " '##লেট',\n",
       " 'থেকে',\n",
       " 'বিশেষভাবে',\n",
       " 'লকি',\n",
       " '##যে',\n",
       " 'রাখা',\n",
       " '[UNK]',\n",
       " 'সব',\n",
       " '##র',\n",
       " '##ণের',\n",
       " 'বার',\n",
       " 'উদ',\n",
       " '##ধার',\n",
       " 'করা',\n",
       " 'হযেছে',\n",
       " '।',\n",
       " 'আজ',\n",
       " 'সে',\n",
       " '##াম',\n",
       " '##বার',\n",
       " 'দপ',\n",
       " '##র',\n",
       " 'সা',\n",
       " '##ডে',\n",
       " '[UNK]',\n",
       " 'দিকে',\n",
       " 'এই',\n",
       " 'সব',\n",
       " '##র',\n",
       " '##ণ',\n",
       " 'উদ',\n",
       " '##ধার',\n",
       " 'করেন',\n",
       " 'কাস',\n",
       " '##টম',\n",
       " '##স',\n",
       " 'গে',\n",
       " '##ায',\n",
       " '##েন',\n",
       " '##দা',\n",
       " 'ও',\n",
       " 'তদ',\n",
       " '##ন',\n",
       " '##ত',\n",
       " 'অধি',\n",
       " '##দ',\n",
       " '##পত',\n",
       " '##রে',\n",
       " '##র',\n",
       " 'করম',\n",
       " '##কর',\n",
       " '##তারা',\n",
       " '।',\n",
       " 'পরত',\n",
       " '##িটি',\n",
       " 'বারের',\n",
       " 'ওজন',\n",
       " '[UNK]',\n",
       " 'গর',\n",
       " '##াম',\n",
       " '।',\n",
       " 'মে',\n",
       " '##াট',\n",
       " 'ওজন',\n",
       " 'চার',\n",
       " 'কেজি',\n",
       " '[UNK]',\n",
       " 'গর',\n",
       " '##াম',\n",
       " 'বলে',\n",
       " 'জানা',\n",
       " 'গেছে']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "bnbert_tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "# text = \"আমি বাংলায় গান গাই।\"\n",
    "# bnbert_tokenizer.tokenize(text)\n",
    "# ['আমি', 'বাংলা', '##য', 'গান', 'গাই', '।']\n",
    "\n",
    "text = dataset['train'][1]['content']\n",
    "text\n",
    "# 'শাহজালাল আন্তর্জাতিক বিমানবন্দরে বিমান বাংলাদেশ এয়ারলাইনসের একটি ফ্লাইটের টয়লেট থেকে বিশেষভাবে লুকিয়ে রাখা ৪০টি স্বর্ণের বার উদ্ধার করা হয়েছে। আজ সোমবার দুপুর সাড়ে ১২টার দিকে এই স্বর্ণ উদ্ধার করেন কাস্টমস গোয়েন্দা ও তদন্ত অধিদপ্তরের কর্মকর্তারা।প্রতিটি বারের ওজন ১১৬ গ্রাম। মোট ওজন চার কেজি ৬৪০ গ্রাম বলে জানা গেছে'\n",
    "bnbert_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "texts = dataset['train']['content']\n",
    "# texts\n",
    "labels = dataset['train']['title']\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pytorch install\n",
    "# ! pip install torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have your training data in two lists: texts (the texts) and labels (the corresponding labels)\n",
    "inputs = bnbert_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# import torch\n",
    "\n",
    "# Assuming labels is your list of string labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "labels_tensor = torch.tensor(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "model = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get sentence embeddings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      3\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Perform clustering\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Get sentence embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs).last_hidden_state[:, 0, :]\n",
    "\n",
    "# Perform clustering\n",
    "kmeans = KMeans(n_clusters=3)  # Change the number of clusters as needed\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Now, 'clusters' contains the cluster assignments for each sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
